   #GitHub
   [https://github.com/guillaume-chevalier/awesome-deep-learning-resources
   /commits/master.atom]Recent Commits to
   Awesome-Deep-Learning-Resources:master

   [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-lear
   ning-resources#start-of-content]Skip to content
   [https://github.com/]
     * Business
     * Marketplace
     * Pricing

   T
   his repository ____________________
   Sign in or
   Sign up

     * Watch
       92
     * Star
       812
     * Fork
       165

Awesome-Deep-Learning-Resources

   C
   ode
   [file://localhost/guillaume-chevalier/awesome-deep-learning-resources/i
   ssues]Issues 0
   [file://localhost/guillaume-chevalier/awesome-deep-learning-resources/p
   ulls]Pull requests 2
   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/p
   rojects]Projects 0
   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/p
   ulse]Insights
   (BUTTON) Dismiss

Join GitHub today

   GitHub is home to over 20 million developers working together to host
   and review code, manage projects, and build software together.

   Sign up
   Rough list of my favorite deep learning resources, useful for
   revisiting topics or for reference. I have got through all of the
   content listed there, carefully. - Guillaume Chevalier
   awesome-list
   machine-learning
   cnn
     * 63 commits
     * 1 branch
     * 0 releases
     * 2 contributors
     * CC0-1.0

   Clone or download

Clone with HTTPS [https://help.github.com/articles/which-remote-url-should-i-use]

   Use Git or checkout with SVN using the web URL.
   https://github.com/g
   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/a
   rchive/master.zip]Download ZIP

Launching GitHub Desktop...

   If nothing happens, [https://desktop.github.com/]download GitHub
   Desktop and try again.

   (BUTTON) Go back

Launching GitHub Desktop...

   If nothing happens, [https://desktop.github.com/]download GitHub
   Desktop and try again.

   (BUTTON) Go back

Launching Xcode...

   If nothing happens, [https://developer.apple.com/xcode/]download Xcode
   and try again.

   (BUTTON) Go back

Launching Visual Studio...

   If nothing happens, [https://visualstudio.github.com/]download the
   GitHub extension for Visual Studio and try again.

   (BUTTON) Go back
   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/f
   ind/master]Find file
   (BUTTON) Branch: master
   Switch branches/tags
   ____________________
     * Branches
     * Tags

   [file://localhost/guillaume-chevalier/awesome-deep-learning-resources/t
   ree/master]master
   Nothing to show
   Nothing to show
   (BUTTON) New pull request
   Latest commit
   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/c
   ommit/1404703f7bd334805e0b78509fb71f8806c34550]1404703 Jan 28, 2018
   @guillaume-chevalier
   guillaume-chevalier committed Jan 28,
   2018
   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/c
   ommit/1404703f7bd334805e0b78509fb71f8806c34550]Update Deep Learning
   Specialization
   Permalink
   Failed to load latest commit information.
   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/b
   lob/master/CONTRIBUTING.md]CONTRIBUTING.md
   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/c
   ommit/c210ac689b155857709183c74e76c4cc94918004]Created CONTRIBUTING.md
   Sep 28, 2017
   LICENSE
   Creative Commons Zero
   v1.0 Universal May 7, 2017
   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/b
   lob/master/README.md]README.md
   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/c
   ommit/1404703f7bd334805e0b78509fb71f8806c34550]Update Deep Learning
   Specialization Jan 29, 2018
   google_trends.png
   Image for trends is now
   high-DPI. Oct 5, 2017

README.md

Awesome

   This is a rough list of my favorite deep learning resources. It has
   been useful to me for learning how to do deep learning, I use it for
   revisiting topics or for reference. I
   ([https://github.com/guillaume-chevalier]Guillaume Chevalier) have
   built this list and got through all of the content listed here,
   carefully.

Contents

     * [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-
       learning-resources#trends]Trends
     * [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-
       learning-resources#online-classes]Online classes
     * [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-
       learning-resources#books]Books
     * [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-
       learning-resources#posts-and-articles]Posts and Articles
     * [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-
       learning-resources#practical-resources]Practical resources
          + [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-
            deep-learning-resources#librairies-and-implementations]Librair
            ies and Implementations
          + Some Datasets
     * Other Math Theory
          + [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-
            deep-learning-resources#gradient-descent-algorithms-and-optimi
            zation]Gradient Descent Algorithms and optimization
          + [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-
            deep-learning-resources#complex-numbers-and-digital-signal-pro
            cessing]Complex Numbers & Digital Signal Processing
     * Papers
          + Recurrent
            Neural Networks
          + [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-
            deep-learning-resources#convolutional-neural-networks]Convolut
            ional Neural Networks
     * YouTube and Videos
     * Misc. Hubs and Links
     * License

Trends

   [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-lear
   ning-resources#trends]Here are the all-time
   [https://www.google.ca/trends/explore?date=all&q=machine%20learning,dee
   p%20learning,data%20science,computer%20programming]Google Trends, from
   2004 up to now, September 2017:

   [file://localhost/guillaume-chevalier/Awesome-Deep-Learning-Resources/b
              lob/master/google_trends.png][google_trends.png]

   You might also want to look at Andrej Karpathy's
   [https://medium.com/@karpathy/a-peek-at-trends-in-machine-learning-ab8a
   1085a106]new post about trends in Machine Learning research.

   I believe that Deep learning is the key to make computers think more
   like humans, and has a lot of potential. Some hard automation tasks can
   be solved easily with that while this was impossible to achieve earlier
   with classical algorithms.

   Moore's Law about exponential progress rates in computer science
   hardware is now more affecting GPUs than CPUs because of physical
   limits on how tiny an atomic transistor can be. We are shifting toward
   parallel architectures
   [[https://www.quora.com/Does-Moores-law-apply-to-GPUs-Or-only-CPUs]read
   more]. Deep learning exploits parallel architectures as such under the
   hood by using GPUs. On top of that, deep learning algorithms may use
   Quantum Computing and apply to machine-brain interfaces in the future.

   I find that the key of intelligence and cognition is a very interesting
   subject to explore and is not yet well understood. Those technologies
   are promising.

Online Classes

   
     * [https://www.coursera.org/learn/m
       achine-learning]Machine Learning by Andrew Ng on Coursera - Renown
       entry-level online class with
       [https://www.coursera.org/account/accomplishments/verify/DXPXHYFNGK
       G3]certificate. Taught by: Andrew Ng, Associate Professor, Stanford
       University; Chief Scientist, Baidu; Chairman and Co-founder,
       Coursera.
     * [https://www.coursera.org/specializations/deep-learning]Deep
       Learning Specialization by Andrew Ng on Coursera - New Deep
       Learning series of courses
       ([https://www.coursera.org/account/accomplishments/records/ZXKXMPVX
       FL8T]1,
       [https://www.coursera.org/account/accomplishments/records/9AMGUFTFX
       RQH]2,
       [https://www.coursera.org/account/accomplishments/records/J69EJSCNR
       CW6]3,
       [https://www.coursera.org/account/accomplishments/records/J69EJSCNR
       CW6]4, 5) by Andrew Ng, now with Python rather than Matlab/Octave.
     * [https://www.udacity.com/course/deep-learning--ud730]Deep Learning
       by Google - Good intermediate to advanced-level course covering
       high-level deep learning concepts, I found it helps to get creative
       once the basics are acquired.
     * [https://www.udacity.com/course/machine-learning-for-trading--ud501
       ]Machine Learning for Trading by Georgia Tech - Interesting class
       for acquiring basic knowledge of machine learning applied to
       trading and some AI and finance concepts. I especially liked the
       section on Q-Learning.
     * [https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAP
       rNmUBH]Neural networks class by Hugo Larochelle, Université de
       Sherbrooke - Interesting class about neural networks available
       online for free by Hugo Larochelle, yet I have watched a few of
       those videos.

Books

   
     * [https://www.amazon.com/How-Create-Mind-Th
       ought-Revealed/dp/B009VSFXZ4]How to Create a Mind - The audio
       version is nice to listen to while commuting. This book is
       motivating about reverse-engineering the mind and thinking on how
       to code AI.
     * [http://neuralnetworksanddeeplearning.com/index.html]Neural
       Networks and Deep Learning - This book covers many of the core
       concepts behind neural networks and deep learning.
     * [http://www.deeplearningbook.org/]Deep Learning - An MIT Press book
       - Yet halfway through the book, it contains satisfying math content
       on how to think about actual deep learning.
     * [https://books.google.ca/books?hl=en&as_coll=4&num=10&uid=103409002
       069648430166&source=gbs_slider_cls_metadata_4_mylibrary_title]Some
       other books I have read - Some books listed here are less related
       to deep learning but are still somehow relevant to this list.

Posts and Articles

   [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-lear
       ning-resources#posts-and-articles]
     * [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-
       learning-resources#posts-and-articles][https://en.wikipedia.org/wik
       i/Predictions_made_by_Ray_Kurzweil]Predictions made by Ray Kurzweil
       - List of mid to long term futuristic predictions made by Ray
       Kurzweil.
     * [http://karpathy.github.io/2015/05/21/rnn-effectiveness/]The
       Unreasonable Effectiveness of Recurrent Neural Networks - MUST READ
       post by Andrej Karpathy - this is what motivated me to learn RNNs,
       it demonstrates what it can achieve in the most basic form of NLP.
     * [http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/]Neural
       Networks, Manifolds, and Topology - Fresh look on how neurons map
       information.
     * [http://colah.github.io/posts/2015-08-Understanding-LSTMs/]Understa
       nding LSTM Networks - Explains the LSTM cells' inner workings,
       plus, it has interesting links in conclusion.
     * [http://distill.pub/2016/augmented-rnns/]Attention and Augmented
       Recurrent Neural Networks - Interesting for visual animations, it
       is a nice intro to attention mechanisms as an example.
     * [http://benanne.github.io/2014/08/05/spotify-cnns.html]Recommending
       music on Spotify with deep learning - Awesome for doing clustering
       on audio - post by an intern at Spotify.
     * [https://research.googleblog.com/2016/05/announcing-syntaxnet-world
       s-most.html]Announcing SyntaxNet: The World's Most Accurate Parser
       Goes Open Source - Parsey McParseface's birth, a neural syntax tree
       parser.
     * [https://research.googleblog.com/2016/08/improving-inception-and-im
       age.html]Improving Inception and Image Classification in TensorFlow
       - Very interesting CNN architecture (e.g.: the inception-style
       convolutional layers is promising and efficient in terms of
       reducing the number of parameters).
     * [https://deepmind.com/blog/wavenet-generative-model-raw-audio/]Wave
       Net: A Generative Model for Raw Audio - Realistic talking machines:
       perfect voice generation.
     * [https://twitter.com/fchollet]François Chollet's Twitter - Author
       of Keras - has interesting Twitter posts and innovative ideas.
     * [http://waitbutwhy.com/2017/04/neuralink.html]Neuralink and the
       Brain's Magical Future - Thought provoking article about the future
       of the brain and brain-computer interfaces.
     * [http://vooban.com/en/tips-articles-geek-stuff/migrating-to-git-lfs
       -for-developing-deep-learning-applications-with-large-files/]Migrat
       ing to Git LFS for Developing Deep Learning Applications with Large
       Files - Easily manage huge files in your private Git projects.
     * [https://blog.keras.io/the-future-of-deep-learning.html]The future
       of deep learning - François Chollet's thoughts on the future of
       deep learning.
     * [http://vooban.com/en/tips-articles-geek-stuff/discover-structure-b
       ehind-data-with-decision-trees/]Discover structure behind data with
       decision trees - Grow decision trees and visualize them, infer the
       hidden logic behind data.
     * [http://vooban.com/en/tips-articles-geek-stuff/hyperopt-tutorial-fo
       r-optimizing-neural-networks-hyperparameters/]Hyperopt tutorial for
       Optimizing Neural Networks' Hyperparameters - Learn to slay down
       hyperparameter spaces automatically rather than by hand.
     * [https://medium.com/@surmenok/estimating-optimal-learning-rate-for-
       a-deep-neural-network-ce32f2556ce0]Estimating an Optimal Learning
       Rate For a Deep Neural Network - Clever trick to estimate an
       optimal learning rate prior any single full training.

Practical Resources

Librairies and Implementations

   [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-lear
       ning-resources#librairies-and-implementations]
     * [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-
       learning-resources#librairies-and-implementations][https://github.c
       om/tensorflow/tensorflow]TensorFlow's GitHub repository - Most
       known deep learning framework, both high-level and low-level while
       staying flexible.
     * [https://github.com/tensorflow/skflow]skflow - TensorFlow wrapper à
       la scikit-learn.
     * [https://keras.io/]Keras - Keras is another intersting deep
       learning framework like TensorFlow, it is mostly high-level.
     * [https://github.com/carpedm20]carpedm20's repositories - Many
       interesting neural network architectures are implemented by the
       Korean guy Taehoon Kim, A.K.A. carpedm20.
     * [https://github.com/carpedm20/NTM-tensorflow]carpedm20/NTM-tensorfl
       ow - Neural Turing Machine TensorFlow implementation.
     * [http://oduerr.github.io/blog/2016/04/06/Deep-Learning_for_lazybone
       s]Deep learning for lazybones - Transfer learning tutorial in
       TensorFlow for vision from high-level embeddings of a pretrained
       CNN, AlexNet 2012.
     * [https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recogni
       tion]LSTM for Human Activity Recognition (HAR) - Tutorial of mine
       on using LSTMs on time series for classification.
     * [https://github.com/guillaume-chevalier/HAR-stacked-residual-bidir-
       LSTMs]Deep stacked residual bidirectional LSTMs for HAR -
       Improvements on the previous project.
     * [https://github.com/guillaume-chevalier/seq2seq-signal-prediction]S
       equence to Sequence (seq2seq) Recurrent Neural Network (RNN) for
       Time Series Prediction - Tutorial of mine on how to predict
       temporal sequences of numbers - that may be multichannel.
     * [https://github.com/Vooban/Hyperopt-Keras-CNN-CIFAR-100]Hyperopt
       for a Keras CNN on CIFAR-100 - Auto (meta) optimizing a neural net
       (and its architecture) on the CIFAR-100 dataset.
     * [https://github.com/guillaume-chevalier?direction=desc&page=1&q=mac
       hine+OR+deep+OR+learning+OR+rnn+OR+lstm+OR+cnn&sort=stars&tab=stars
       &utf8=%E2%9C%93]ML / DL repositories I starred - GitHub is full of
       nice code samples & projects.
     * [https://github.com/Vooban/Smoothly-Blend-Image-Patches]Smoothly
       Blend Image Patches - Smooth patch merger for
       [https://vooban.com/en/tips-articles-geek-stuff/satellite-image-seg
       mentation-workflow-with-u-net/]semantic segmentation with a U-Net.

Some Datasets

   Those are resources I have found that seems interesting to develop
   models onto.
   [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-lear
       ning-resources#some-datasets]
     * [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-
       learning-resources#some-datasets][https://archive.ics.uci.edu/ml/da
       tasets.html]UCI Machine Learning Repository - TONS of datasets for
       ML.
     * [http://www.cs.cornell.edu/%7Ecristian/Cornell_Movie-Dialogs_Corpus
       .html]Cornell Movie--Dialogs Corpus - This could be used for a
       chatbot.
     * [https://rajpurkar.github.io/SQuAD-explorer/]SQuAD The Stanford
       Question Answering Dataset - Question answering dataset that can be
       explored online, and a list of models performing well on that
       dataset.
     * [http://www.openslr.org/12/]LibriSpeech ASR corpus - Huge free
       English speech dataset with balanced genders and speakers, that
       seems to be of high quality.
     * [https://github.com/caesar0301/awesome-public-datasets]Awesome
       Public Datasets - An awesome list of public datasets.

Other Math Theory

Gradient Descent Algorithms & Optimization Theory

     * [http://neuralnetworksanddeeplearning.com/chap2.html]Neural
       Networks and Deep Learning, ch.2 - Overview on how does the
       backpropagation algorithm works.
     * [http://neuralnetworksanddeeplearning.com/chap4.html]Neural
       Networks and Deep Learning, ch.4 - A visual proof that neural nets
       can compute any function.
     * [https://medium.com/@karpathy/yes-you-should-understand-backprop-e2
       f06eab496b#.mr5wq61fb]Yes you should understand backprop - Exposing
       backprop's caveats and the importance of knowing that while
       training models.
     * [http://briandolhansky.com/blog/2013/9/27/artificial-neural-network
       s-backpropagation-part-4]Artificial Neural Networks: Mathematics of
       Backpropagation - Picturing backprop, mathematically.
     * [https://www.youtube.com/watch?v=56TYLaQN4N8]Deep Learning Lecture
       12: Recurrent Neural Nets and LSTMs - Unfolding of RNN graphs is
       explained properly, and potential problems about gradient descent
       algorithms are exposed.
     * [http://sebastianruder.com/content/images/2016/09/saddle_point_eval
       uation_optimizers.gif]Gradient descent algorithms in a saddle point
       - Visualize how different optimizers interacts with a saddle
       points.
     * [https://devblogs.nvidia.com/wp-content/uploads/2015/12/NKsFHJb.gif
       ]Gradient descent algorithms in an almost flat landscape -
       Visualize how different optimizers interacts with an almost flat
       landscape.
     * [https://www.youtube.com/watch?v=F6GSRDoB-Cg]Gradient Descent -
       Okay, I already listed Andrew NG's Coursera class above, but this
       video especially is quite pertinent as an introduction and defines
       the gradient descent algorithm.
     * [https://www.youtube.com/watch?v=YovTqTY-PYY]Gradient Descent:
       Intuition - What follows from the previous video: now add
       intuition.
     * [https://www.youtube.com/watch?v=gX6fZHgfrow]Gradient Descent in
       Practice 2: Learning Rate - How to adjust the learning rate of a
       neural network.
     * [https://www.youtube.com/watch?v=u73PU6Qwl1I]The Problem of
       Overfitting - A good explanation of overfitting and how to address
       that problem.
     * [https://www.youtube.com/watch?v=ewogYw5oCAI]Diagnosing Bias vs
       Variance - Understanding bias and variance in the predictions of a
       neural net and how to address those problems.
     * [https://arxiv.org/pdf/1706.02515.pdf]Self-Normalizing Neural
       Networks - Appearance of the incredible SELU activation function.
     * [https://arxiv.org/pdf/1606.04474.pdf]Learning to learn by gradient
       descent by gradient descent - RNN as an optimizer: introducing the
       L2L optimizer, a meta-neural network.

Complex Numbers & Digital Signal Processing

   Okay, signal processing might not be directly related to deep learning,
   but studying it is interesting to have more intuition in developing
   neural architectures based on signal.
     * [https://en.wikipedia.org/wiki/Window_function]Window Functions -
       Wikipedia page that lists some of the known window functions.
     * [https://acko.net/files/gltalks/toolsforthought/]MathBox, Tools for
       Thought Graphical Algebra and Fourier Analysis - New look on
       Fourier analysis.
     * [http://acko.net/blog/how-to-fold-a-julia-fractal/]How to Fold a
       Julia Fractal - Animations dealing with complex numbers and wave
       equations.
     * [http://acko.net/blog/animate-your-way-to-glory/]Animate Your Way
       to Glory, Math and Physics in Motion - Convergence methods in
       physic engines, and applied to interaction design.
     * [http://acko.net/blog/animate-your-way-to-glory-pt2/]Animate Your
       Way to Glory - Part II, Math and Physics in Motion - Nice
       animations for rotation and rotation interpolation with
       Quaternions, a mathematical object for handling 3D rotations.
     * [https://github.com/guillaume-chevalier/filtering-stft-and-laplace-
       transform]Filtering signal, plotting the STFT and the Laplace
       transform - Simple Python demo on signal processing.

Papers

Recurrent Neural Networks

   [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-lear
       ning-resources#recurrent-neural-networks]
     * [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-
       learning-resources#recurrent-neural-networks][https://arxiv.org/pdf
       /1404.7828v4.pdf]Deep Learning in Neural Networks: An Overview -
       You_Again's summary/overview of deep learning, mostly about RNNs.
     * [http://www.di.ufpe.br/%7Efnj/RNA/bibliografia/BRNN.pdf]Bidirection
       al Recurrent Neural Networks - Better classifications with RNNs
       with bidirectional scanning on the time axis.
     * [https://arxiv.org/pdf/1406.1078v3.pdf]Learning Phrase
       Representations using RNN Encoder-Decoder for Statistical Machine
       Translation - Two networks in one combined into a seq2seq (sequence
       to sequence) Encoder-Decoder architecture. RNN Encoder-Decoder with
       1000 hidden units. Adadelta optimizer.
     * [http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-wit
       h-neural-networks.pdf]Sequence to Sequence Learning with Neural
       Networks - 4 stacked LSTM cells of 1000 hidden size with reversed
       input sentences, and with beam search, on the WMT'14 English to
       French dataset.
     * [https://arxiv.org/pdf/1602.02410.pdf]Exploring the Limits of
       Language Modeling - Nice recursive models using word-level LSTMs on
       top of a character-level CNN using an overkill amount of GPU power.
     * [https://cs224d.stanford.edu/reports/PradhanLongpre.pdf]Exploring
       the Depths of Recurrent Neural Networks with Stochastic Residual
       Learning - Basically, residual connections can be better than
       stacked RNNs in the presented case of sentiment analysis.
     * [https://arxiv.org/pdf/1409.0473.pdf]Neural Machine Translation by
       Jointly Learning to Align and Translate - Attention mechanism for
       LSTMs! Mostly, figures and formulas and their explanations revealed
       to be useful to me. I gave a talk on that paper
       [https://www.youtube.com/watch?v=QuvRWevJMZ4]here.
     * [https://arxiv.org/pdf/1502.03044.pdf]Show, Attend and Tell: Neural
       Image Caption Generation with Visual Attention - LSTMs' attention
       mechanisms on CNNs feature maps does wonders.
     * [https://arxiv.org/pdf/1508.04025.pdf]Effective Approaches to
       Attention-based Neural Machine Translation - Exploring different
       approaches to attention mechanisms.
     * [https://arxiv.org/pdf/1410.5401v2.pdf]Neural Turing Machines -
       Outstanding for letting a neural network learn an algorithm with
       seemingly good generalization over long time dependencies.
       Sequences recall problem.
     * [https://arxiv.org/pdf/1506.03340v3.pdf]Teaching Machines to Read
       and Comprehend - A very interesting and creative work about textual
       question answering, what a breakthrough, there is something to do
       with that.
     * [https://arxiv.org/pdf/1601.06759.pdf]Pixel Recurrent Neural
       Networks - Nice for photoshop-like "content aware fill" to fill
       missing patches in images.
     * [https://arxiv.org/pdf/1603.08983v4.pdf]Adaptive Computation Time
       for Recurrent Neural Networks - Let RNNs decide how long do they
       compute. I would love to see how well would it combines to Neural
       Turing Machines. Interesting interactive visualizations on the
       subject can be found [http://distill.pub/2016/augmented-rnns/]here.
     * [http://www.nature.com/articles/nature20101.epdf?author_access_toke
       n=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSur
       J3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz]Hyb
       rid computing using a neural network with dynamic external memory -
       Improvements on differentiable memory based on NTMs: now it is the
       Differentiable Neural Computer (DNC).
     * [https://arxiv.org/pdf/1609.08144.pdf]Google's Neural Machine
       Translation System: Bridging the Gap between Human and Machine
       Translation - In 2016: stacked residual LSTMs with attention
       mechanisms on encoder/decoder are the best for NMT (Neural Machine
       Translation).
     * [https://arxiv.org/pdf/1703.01619.pdf]Neural Machine Translation
       and Sequence-to-sequence Models: A Tutorial - Interesting overview
       of the subject of NMT, I mostly read part 8 about RNNs with
       attention as a refresher.
     * [https://arxiv.org/pdf/1703.03906.pdf]Massive Exploration of Neural
       Machine Translation Architectures - That yields intuition about the
       boundaries of what works for doing NMT within a framed seq2seq
       problem formulation.

Convolutional Neural Networks

   
     * [http://yann.lecun
       .com/exdb/publis/pdf/jarrett-iccv-09.pdf]What is the Best
       Multi-Stage Architecture for Object Recognition? - Awesome for the
       use of "local contrast normalization".
     * [http://www.cs.toronto.edu/%7Efritz/absps/imagenet.pdf]ImageNet
       Classification with Deep Convolutional Neural Networks - AlexNet,
       2012 ILSVRC, breakthrough of the ReLU activation function.
     * [https://arxiv.org/pdf/1311.2901v3.pdf]Visualizing and
       Understanding Convolutional Networks - For the "deconvnet layer".
     * [https://arxiv.org/pdf/1511.07289v1.pdf]Fast and Accurate Deep
       Network Learning by Exponential Linear Units - ELU activation
       function for CIFAR vision tasks.
     * [https://arxiv.org/pdf/1409.1556v6.pdf]Very Deep Convolutional
       Networks for Large-Scale Image Recognition - Interesting idea of
       stacking multiple 3x3 conv+ReLU before pooling for a bigger filter
       size with just a few parameters. There is also a nice table for
       "ConvNet Configuration".
     * [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/S
       zegedy_Going_Deeper_With_2015_CVPR_paper.pdf]Going Deeper with
       Convolutions - GoogLeNet: Appearance of "Inception" layers/modules,
       the idea is of parallelizing conv layers into many mini-conv of
       different size with "same" padding, concatenated on depth.
     * [https://arxiv.org/pdf/1505.00387v2.pdf]Highway Networks - Highway
       networks: residual connections.
     * [https://arxiv.org/pdf/1502.03167v3.pdf]Batch Normalization:
       Accelerating Deep Network Training by Reducing Internal Covariate
       Shift - Batch normalization (BN): to normalize a layer's output by
       also summing over the entire batch, and then performing a linear
       rescaling and shifting of a certain trainable amount.
     * [https://arxiv.org/pdf/1505.04597.pdf]U-Net: Convolutional Networks
       for Biomedical Image Segmentation - The U-Net is an encoder-decoder
       CNN that also has skip-connections, good for image segmentation at
       a per-pixel level.
     * [https://arxiv.org/pdf/1512.03385v1.pdf]Deep Residual Learning for
       Image Recognition - Very deep residual layers with batch
       normalization layers - a.k.a. "how to overfit any vision dataset
       with too many layers and make any vision model work properly at
       recognition given enough data".
     * [https://arxiv.org/pdf/1602.07261v2.pdf]Inception-v4,
       Inception-ResNet and the Impact of Residual Connections on Learning
       - For improving GoogLeNet with residual connections.
     * [https://arxiv.org/pdf/1609.03499v2.pdf]WaveNet: a Generative Model
       for Raw Audio - Epic raw voice/music generation with new
       architectures based on dilated causal convolutions to capture more
       audio length.
     * [https://arxiv.org/pdf/1610.07584v2.pdf]Learning a Probabilistic
       Latent Space of Object Shapes via 3D Generative-Adversarial
       Modeling - 3D-GANs for 3D model generation and fun 3D furniture
       arithmetics from embeddings (think like word2vec word arithmetics
       with 3D furniture representations).
     * [https://research.fb.com/publications/ImageNet1kIn1h/]Accurate,
       Large Minibatch SGD: Training ImageNet in 1 Hour - Incredibly fast
       distributed training of a CNN.
     * [https://arxiv.org/pdf/1608.06993.pdf]Densely Connected
       Convolutional Networks - Best Paper Award at CVPR 2017, yielding
       improvements on state-of-the-art performances on CIFAR-10,
       CIFAR-100 and SVHN datasets, this new neural network architecture
       is named DenseNet.
     * [https://arxiv.org/pdf/1611.09326.pdf]The One Hundred Layers
       Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation -
       Merges the ideas of the U-Net and the DenseNet, this new neural
       network is especially good for huge datasets in image segmentation.

YouTube and Videos

     * [https://www.youtube.com/watch?v=QuvRWevJMZ4]Attention Mechanisms
       in Recurrent Neural Networks (RNNs) - IGGG - A talk for a reading
       group on attention mechanisms (Paper: Neural Machine Translation by
       Jointly Learning to Align and Translate).
     * [https://www.youtube.com/playlist?list=PLlXfTHzgMRULkodlIEqfgTS-H1A
       Y_bNtq]Tensor Calculus and the Calculus of Moving Surfaces -
       Generalize properly how Tensors work, yet just watching a few
       videos already helps a lot to grasp the concepts.
     * [https://www.youtube.com/playlist?list=PLlp-GWNOd6m4C_-9HxuHg2_ZeI2
       Yzwwqt]Deep Learning & Machine Learning (Advanced topics) - A list
       of videos about deep learning that I found interesting or useful,
       this is a mix of a bit of everything.
     * [https://www.youtube.com/playlist?list=PLlp-GWNOd6m6gSz0wIcpvl4ixSl
       S-HEmr]Signal Processing Playlist - A YouTube playlist I composed
       about DFT/FFT, STFT and the Laplace transform - I was mad about my
       software engineering bachelor not including signal processing
       classes (except a bit in the quantum physics class).
     * [https://www.youtube.com/playlist?list=PLlp-GWNOd6m7vLOsW20xAJ81-65
       C-Ys6k]Computer Science - Yet another YouTube playlist I composed,
       this time about various CS topics.
     * [https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A/videos?vi
       ew=0&sort=p&flow=grid]Siraj's Channel - Siraj has entertaining,
       fast-paced video tutorials about deep learning.
     * [https://www.youtube.com/user/keeroyz/videos?sort=p&view=0&flow=gri
       d]Two Minute Papers' Channel - Interesting and shallow overview of
       some research papers, for example about WaveNet or Neural Style
       Transfer.
     * [https://www.coursera.org/learn/neural-networks-deep-learning/lectu
       re/dcm5r/geoffrey-hinton-interview]Geoffrey Hinton interview -
       Andrew Ng interviews Geoffrey Hinton, who talks about his research
       and breaktroughs, and gives advice for students.

Misc. Hubs & Links

     * [https://news.ycombinator.com/news]Hacker News - Maybe how I
       discovered ML - Interesting trends appear on that site way before
       they get to be a big deal.
     * [http://www.datatau.com/]DataTau - This is a hub similar to Hacker
       News, but specific to data science.
     * [http://www.naver.com/]Naver - This is a Korean search engine -
       best used with Google Translate, ironically. Surprisingly,
       sometimes deep learning search results and comprehensible advanced
       math content shows up more easily there than on Google search.
     * [http://www.arxiv-sanity.com/]Arxiv Sanity Preserver - arXiv
       browser with TF/IDF features.

License

   [https://creativecommons.org/publicdomain/zero/1
   .0/]CC0

   To the extent possible under law,
   [https://github.com/guillaume-chevalier]Guillaume Chevalier has waived
   all copyright and related or neighboring rights to this work.

     * © 2018 GitHub, Inc.
     * [https://github.com/site/terms]Terms
     * [https://github.com/site/privacy]Privacy
     * [https://help.github.com/articles/github-security/]Security
     * [https://status.github.com/]Status
     * [https://help.github.com/]Help

   [https://github.com/]
     * [https://github.com/contact]Contact GitHub
     * [https://developer.github.com/]API
     * [https://training.github.com/]Training
     * [https://shop.github.com/]Shop
     * [https://blog.github.com/]Blog
     * [https://github.com/about]About

   (BUTTON) You can't perform that action at this time.

   You signed in with another tab or window.
   Reload to refresh your session. You signed out in
   another tab or window.
   [file://localhost/Users/admin/Pros/sh/awesome/awe_raw/awesome-deep-lear
   ning-resources]Reload to refresh your session.

   (BUTTON)

   Press h to open a hovercard with more details.
